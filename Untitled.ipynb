{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Test error: 89.93\n",
      "Test error: 71.69\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "\n",
    "def representations_to_adj(representations, sigma=1):\n",
    "    rview = representations.view(representations.size(0),-1)\n",
    "    rview =  torch.nn.functional.normalize(rview, p=2, dim=1)\n",
    "    adj = torch.mm(rview,torch.t(rview))\n",
    "#    adj = torch.exp(-distances)\n",
    "    ind = np.diag_indices(adj.shape[0])\n",
    "    adj[ind[0], ind[1]] = torch.zeros(adj.shape[0]).cuda()\n",
    "    degree = torch.pow(adj.sum(dim=1),-0.5)\n",
    "    degree_matrix = torch.diag(degree)\n",
    "    return torch.matmul(degree_matrix,torch.matmul(adj,degree_matrix))\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "teacher_file = \"checkpoint/WideResNet28-10.pth\"\n",
    "teacher_model = torch.load(teacher_file)[\"net\"].module\n",
    "\n",
    "#student_file = \"checkpoint/HKD_28-10_teaches_28-1_16_4.pth\"\n",
    "student_file = \"checkpoint/WideResNet28-1.pth\"\n",
    "#student_file = \"checkpoint/GKD_28-10_teaches_28-1_0_0_p1_25.pth\"\n",
    "student_model = torch.load(student_file)[\"net\"].module\n",
    "student_model.eval()\n",
    "teacher_model.eval()\n",
    "\n",
    "def to_one_hot(inp,num_classes):\n",
    "    y_onehot = torch.cuda.FloatTensor(inp.size(0), num_classes)\n",
    "    y_onehot.zero_()\n",
    "\n",
    "    y_onehot.scatter_(1, inp.unsqueeze(1), 1)\n",
    "    \n",
    "    return y_onehot\n",
    "\n",
    "trainloader, testloader = utils.load_data(128)\n",
    "identity = torch.eye(1000).cuda()\n",
    "utils.test(teacher_model,testloader, \"cuda\", \"no\",show=\"error\")\n",
    "utils.test(student_model,testloader, \"cuda\", \"no\",show=\"error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957203\n",
      "0.99935067\n",
      "1.0016841\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs_teacher, layers_teacher = teacher_model(inputs)\n",
    "        outputs_student, layers_student = student_model(inputs)\n",
    "        for student_layer,teacher_layer in zip(layers_student,layers_teacher):\n",
    "            adj_teacher = representations_to_adj(teacher_layer)\n",
    "            laplacian_teacher = adj_teacher\n",
    "            laplacian_teacher = laplacian_teacher.cpu().numpy()\n",
    "\n",
    "            w, v = linalg.eig(laplacian_teacher)\n",
    "            seen = {}\n",
    "            unique_eigenvalues = []\n",
    "            for (x, y) in zip(w, v):\n",
    "                if x in seen:\n",
    "                    continue\n",
    "                seen[x] = 1\n",
    "                unique_eigenvalues.append((x, y))\n",
    "            fiedler_vector = sorted(unique_eigenvalues)[1][1].reshape(1000,1)\n",
    "\n",
    "            adj_student = representations_to_adj(student_layer)\n",
    "            laplacian_student = identity - adj_student\n",
    "            laplacian_student = laplacian_student.cpu().numpy()\n",
    "            smoothness = np.dot(fiedler_vector.T,laplacian_student)\n",
    "            smoothness = np.dot(smoothness,fiedler_vector)\n",
    "            print(smoothness.sum())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 999)\n",
      "998.8728\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs_teacher, layers_teacher = teacher_model(inputs)\n",
    "        outputs_student, layers_student = student_model(inputs)\n",
    "        for student_layer,teacher_layer in zip(layers_student,layers_teacher):\n",
    "            adj_teacher = representations_to_adj(teacher_layer)\n",
    "            laplacian_teacher = adj_teacher\n",
    "            laplacian_teacher = laplacian_teacher.cpu().numpy()\n",
    "\n",
    "            w, v = linalg.eig(laplacian_teacher)\n",
    "            seen = {}\n",
    "            unique_eigenvalues = []\n",
    "            for (x, y) in zip(w, v):\n",
    "                if x in seen:\n",
    "                    continue\n",
    "                seen[x] = 1\n",
    "                unique_eigenvalues.append((x, y))\n",
    "            eigenvectors = []\n",
    "            for x,y in sorted(unique_eigenvalues)[1:]:\n",
    "                eigenvectors.append(y)\n",
    "            eigenvectors = np.array(eigenvectors).T\n",
    "            print(eigenvectors.shape)\n",
    "\n",
    "            adj_student = representations_to_adj(student_layer)\n",
    "            laplacian_student = identity - adj_student\n",
    "            laplacian_student = laplacian_student.cpu().numpy()\n",
    "            smoothness = np.dot(eigenvectors.T,laplacian_student)\n",
    "            smoothness = np.dot(smoothness,eigenvectors)\n",
    "            print(smoothness.sum())\n",
    "            break\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5094147\n",
      "1.0608368\n",
      "2.1382065\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs_teacher, layers_teacher = teacher_model(inputs)\n",
    "        outputs_student, layers_student = student_model(inputs)\n",
    "        class_signal = to_one_hot(targets,10).cpu().numpy()\n",
    "        for student_layer,teacher_layer in zip(layers_student,layers_teacher):\n",
    "            adj_student = representations_to_adj(student_layer)\n",
    "            laplacian_student = identity - adj_student\n",
    "            laplacian_student = laplacian_student.cpu().numpy()\n",
    "            smoothness = np.dot(class_signal.T,laplacian_student)\n",
    "            smoothness = np.dot(smoothness,class_signal)\n",
    "            print(smoothness.sum())\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.8480, 0.7609,  ..., 0.9352, 0.4785, 0.7277],\n",
       "        [0.8480, 0.0000, 0.3398,  ..., 0.5396, 1.0513, 0.7288],\n",
       "        [0.7609, 0.3398, 0.0000,  ..., 0.6055, 0.9256, 0.6054],\n",
       "        ...,\n",
       "        [0.9352, 0.5396, 0.6055,  ..., 0.0000, 0.9854, 1.0658],\n",
       "        [0.4785, 1.0513, 0.9256,  ..., 0.9854, 0.0000, 1.0013],\n",
       "        [0.7277, 0.7288, 0.6054,  ..., 1.0658, 1.0013, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rview = student_layer.view(student_layer.size(0),-1)\n",
    "distances = torch.cdist(rview,rview)/(2*1**2)\n",
    "distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
